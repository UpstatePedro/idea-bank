{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL\n",
    "\n",
    "Brief summary of key SQL \n",
    "\n",
    "## Intro\n",
    "\n",
    "***Procedural*** programming languages define both the desired outcome and the process by which to achieve it. The procedural paradigm is a subset of the imperative paradigm.\n",
    "\n",
    "***Non-procedural*** languages define the desired outcome, but omit the process - that is left to something/one else to figure out. (similarities with the declarative paradigm)\n",
    "\n",
    "SQL is a non-procedural language: it uses statements to define the expected inputs and outputs; the database engine's ***optimiser*** works out an efficient execution path between the two.\n",
    "\n",
    "The SQL language supports several different types of statements: \n",
    "- ***schema statements*** define the data structures stored in the database\n",
    "- ***data statements*** query & manipulate the data in the database\n",
    "- ***transaction statements*** manage changes to the database using transactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqlite will create a disk-based SQL database - with no server required - that lives in a file. \n",
    "\n",
    "To get started, we'll create a database called 'example.db' and create a connection to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "db_path = 'example.db'\n",
    "print(sqlite3.version_info)\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types\n",
    "\n",
    "\n",
    "### Characters\n",
    "\n",
    "```SQL\n",
    "char(20) /* fixed-length, max 255 bytes*/\n",
    "varchar(280) /* variable-length, max 65 KB*/\n",
    "```\n",
    "\n",
    "### Text\n",
    "\n",
    "```SQL\n",
    "tinytext /* 255 bytes*/\n",
    "text /* 65 KB*/\n",
    "mediumtext /* 16.8 MB*/\n",
    "longtext /* 4.3 GB*/\n",
    "```\n",
    "\n",
    "### Numerical\n",
    "\n",
    "#### Integer types\n",
    "\n",
    "```SQL\n",
    "tinyint\n",
    "smallint\n",
    "mediumint\n",
    "int\n",
    "bigint\n",
    "```\n",
    "\n",
    "#### Floating-point types\n",
    "\n",
    "```SQL\n",
    "float\n",
    "double\n",
    "```\n",
    "\n",
    "### Temporal\n",
    "\n",
    "```SQL\n",
    "date\n",
    "datetime\n",
    "timestamp\n",
    "year\n",
    "time\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tables\n",
    "\n",
    "Shape of a table-creation statement\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE <table_name>\n",
    "(\n",
    "    <col_name> <data_type> <other_args>, /* pattern */\n",
    "    reference_num INT UNSIGNED, /* example 1 */\n",
    "    name VARCHAR(30), /* example 2 */\n",
    "    ...\n",
    ");\n",
    "```\n",
    "\n",
    "### Constraints\n",
    "\n",
    "Alongside the column definition entries, we can also add constraints on their values\n",
    "\n",
    "```SQL\n",
    "CONSTRAINT <constraint_name> PRIMARY KEY (<column_name>) /* Make <column_name> the primary key */\n",
    "CONSTRAINT <constraint_name> PRIMARY KEY (<column_name1>, <column_name2>) /* Create a composite primary key */\n",
    "CONSTRAINT <constraint_name> FOREIGN KEY (<column_name>) REFERENCES <table_name> (<column_name>) /* Constrain the values in a column to those that appear in the column of another table */\n",
    "```\n",
    "\n",
    "To enforce the values that a column can take, there is also a `CHECK` keyword that can be used to specify the list of acceptable values & enforce a check against them.\n",
    "\n",
    "In the case of MySQL, we use `ENUM` instead of `CHECK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tables(conn):\n",
    "    \"\"\"Print a list of table names for the connected DB\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "    \n",
    "check_tables(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to motivate my exploration of SQL, I'm going to create a (weakly realistic, but heavily simplified) synthetic dataset which allows me to take advantage of the various features of the language.\n",
    "\n",
    "### Creating synthetic data for our example db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "COUNTRIES = ('UK', 'FRANCE', 'RUSSIA', 'CANADA', 'BRAZIL', 'AUSTRALIA')\n",
    "YEARS = tuple(i for i in range(2000, 2021))\n",
    "\n",
    "WeatherDistribution = namedtuple('WeatherDistribution', ['temp_mean', 'temp_var', 'precip_mean', 'precip_var'])\n",
    "weather_distributions = {\n",
    "    'UK': WeatherDistribution(10, 25, 700, 1000),\n",
    "    'FRANCE': WeatherDistribution(12, 30, 500, 900),\n",
    "    'RUSSIA': WeatherDistribution(5, 70, 600, 1200),\n",
    "    'CANADA': WeatherDistribution(10, 70, 600, 800)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_temperature_data(month_arr, mean, var):\n",
    "    \"\"\"Generate a synthetic time-series of temperature values\"\"\"\n",
    "    return mean + np.sqrt(var) * np.random.randn(len(month_arr))\n",
    "\n",
    "def generate_precipitation_data(month_arr, mean, var):\n",
    "    \"\"\"Generate a synthetic time-series of precipitation values\"\"\"\n",
    "    return np.clip(mean + np.sqrt(var) * np.random.randn(len(month_arr)), 0., 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>precip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UK</th>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>9.896597</td>\n",
       "      <td>13.600906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>0.911984</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>7.274580</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>2.092990</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>6.254286</td>\n",
       "      <td>17.626213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CANADA</th>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>-8.213065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>4.094668</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>-3.657024</td>\n",
       "      <td>8.848924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>1.748650</td>\n",
       "      <td>7.956259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>10.866185</td>\n",
       "      <td>26.297285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30684 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         temp     precip\n",
       "country date                            \n",
       "UK      2000-01-01   9.896597  13.600906\n",
       "        2000-01-02   0.911984   0.000000\n",
       "        2000-01-03   7.274580   0.000000\n",
       "        2000-01-04   2.092990   0.000000\n",
       "        2000-01-05   6.254286  17.626213\n",
       "...                       ...        ...\n",
       "CANADA  2020-12-27  -8.213065   0.000000\n",
       "        2020-12-28   4.094668   0.000000\n",
       "        2020-12-29  -3.657024   8.848924\n",
       "        2020-12-30   1.748650   7.956259\n",
       "        2020-12-31  10.866185  26.297285\n",
       "\n",
       "[30684 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates = pd.date_range(f'{YEARS[0]}-01-01', f'{YEARS[-1]}-12-31', freq='D')\n",
    "weather_dfs = []\n",
    "for country in COUNTRIES[:4]:\n",
    "    # Get the relevant weather distribution for the country being processed\n",
    "    weather_dist = weather_distributions.get(country)\n",
    "    # Create an index object for the dataframe that will hold the synthetic data\n",
    "    idx = pd.MultiIndex.from_arrays([[country for date in dates], dates], names=('country', 'date'))\n",
    "    # Generate synthetic data\n",
    "    temp = generate_temperature_data(month_arr=idx.get_level_values('date').month, mean=weather_dist.temp_mean, var=weather_dist.temp_var)\n",
    "    precip = generate_precipitation_data(month_arr=idx.get_level_values('date').month, mean=weather_dist.precip_mean/365, var=weather_dist.precip_var)\n",
    "    # Collect a new dataframe with our fresh weather data\n",
    "    weather_dfs.append(pd.DataFrame(data={'temp': temp, 'precip': precip}, index=idx))\n",
    "df = pd.concat(weather_dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_COUNTRY_TABLE = '''\n",
    "CREATE TABLE country\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name VARCHAR(20) NOT NULL\n",
    ");\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_WEATHER_TABLE = '''\n",
    "CREATE TABLE weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    country_id INTEGER,\n",
    "    date DATE NOT NULL,\n",
    "    temp FLOAT,\n",
    "    precip FLOAT,\n",
    "    \n",
    "    CONSTRAINT fk_weather_country FOREIGN KEY (country_id) REFERENCES country (id)\n",
    ");\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(conn, *table_schemas):\n",
    "    \"\"\"Create new SQL tables\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    for schema in table_schemas:\n",
    "        cursor.execute(schema)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tables(conn, CREATE_COUNTRY_TABLE, CREATE_WEATHER_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('country',), ('weather',)]\n"
     ]
    }
   ],
   "source": [
    "tables = check_tables(conn)\n",
    "assert len(tables) == 2\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the data into the tables\n",
    "\n",
    "#### `country` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT_COUNTRY_DATA = '''\n",
    "INSERT INTO country (name) VALUES (?)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.executemany(INSERT_COUNTRY_DATA, [(c,) for c in COUNTRIES])\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UK': 1, 'FRANCE': 2, 'RUSSIA': 3, 'CANADA': 4, 'BRAZIL': 5, 'AUSTRALIA': 6}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_COUNTRIES_QUERY = '''SELECT * from country'''\n",
    "\n",
    "results = cursor.execute(ALL_COUNTRIES_QUERY)\n",
    "country_id_map = {result[1]: result[0] for result in results}\n",
    "country_id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `weather` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT_WEATHER_DATA = '''\n",
    "INSERT INTO weather (country_id, date, temp, precip) VALUES (?, ?, ?, ?)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_weather_record(record):\n",
    "    return (country_id_map[record.country], str(record.date.date()), record.temp, record.precip)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.executemany(INSERT_WEATHER_DATA, map(prepare_weather_record, df.round(1).to_records()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30684,)]\n"
     ]
    }
   ],
   "source": [
    "COUNT_WEATHER_QUERY = '''SELECT COUNT(id) from weather'''\n",
    "\n",
    "result = cursor.execute(COUNT_WEATHER_QUERY).fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating data\n",
    "\n",
    "\n",
    "### Joins\n",
    "\n",
    "One of the joys of normalisation is that we create single instances of information that can be associated with many other records of information elsewhere in the database; having only one place to update each ensures it is always the most up-to-date version and avoids inconsistencies.\n",
    "\n",
    "But it also means that the data we want for a given use-case will often be spread across multiple tables and needs to be brought together to make it useful.\n",
    "\n",
    "**Joins** allow us to do this in the database, rather than in our application code: which is likely to be  more efficient and less error-prone.\n",
    "\n",
    "1. Cartesian product\n",
    "1. Inner join\n",
    "1. Outer join\n",
    "\n",
    "#### Cartesian product\n",
    "\n",
    "If you include a `JOIN` statement in your query, but don't provide an `ON <...> = <...>` clause, then the query will return the cartesian product of the two tables; ie. every possible combination of the two tables.\n",
    "If table 1 has $N$ rows and table 2 has $M$ rows, then we'll end up with a result set of $N \\times M$ rows.\n",
    "\n",
    "This is known as a `cross join`, and is rarely what we intended to ask for...\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    alias_1.col_a\n",
    "    , alis_1.col_b\n",
    "    , alias_2.col_x\n",
    "    , alias_2.col_y\n",
    "FROM\n",
    "    <table_name_1> alias_1\n",
    "    CROSS JOIN\n",
    "    <table_name_2> alias_2\n",
    "```\n",
    "\n",
    "#### Inner join\n",
    "\n",
    "Inner joins are the default join type. If you provide the `ON t.p_id = p.id` clause at the end of the join statement, but don't specify what type of join you would like (ie. `INNER` or `OUTER`), then you will get an inner join (but you ***should*** always say which type of join you want!).\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    alias_1.col_a\n",
    "    , alis_1.col_b\n",
    "    , alias_2.col_x\n",
    "    , alias_2.col_y\n",
    "FROM\n",
    "    <table_name_1> alias_1\n",
    "    INNER JOIN\n",
    "    <table_name_2> alias_2\n",
    "    ON\n",
    "    alias_1.col_name_1 = alias_2.col_name_2;\n",
    "```\n",
    "\n",
    "Returns a record only when a match exists on both sides of the join. Any records with values in the columns on which we're joining that only appear in one of the join tables, then that record will be omitted from the result set.\n",
    "\n",
    "> `IN`ner joins give us the `IN`tersection of the two tables.\n",
    "\n",
    "Because we're dealing with the intersection of the two tables, it doesn't make sense to distinguish between `LEFT` & `RIGHT` joins.\n",
    "\n",
    "#### Outer join\n",
    "\n",
    "Outer joins include the full set of values from specified tables in the join, even when there isn't a match on both sides.\n",
    "For any columns from the table without matches that are included in the results, we'll just get `NULL` values.\n",
    "\n",
    "Flavours:\n",
    "- `LEFT OUTER JOIN`\n",
    "- `RIGHT OUTER JOIN`\n",
    "- `FULL OUTER JOIN`\n",
    "\n",
    "```SQL\n",
    "SELECT\n",
    "    alias_1.col_a\n",
    "    , alis_1.col_b\n",
    "    , alias_2.col_x\n",
    "    , alias_2.col_y\n",
    "FROM\n",
    "    <table_name_1> alias_1\n",
    "    LEFT OUTER JOIN\n",
    "    <table_name_2> alias_2\n",
    "    ON\n",
    "    alias_1.col_name_1 = alias_2.col_name_2;\n",
    "```\n",
    "\n",
    "> left joins are used by convention, so try to avoid right joins in practice\n",
    "\n",
    "If you omit the `OUTER` and just use `LEFT / RIGHT JOIN` then this will always yield an outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_names(cursor):\n",
    "    return [desc[0] for desc in cursor.description]\n",
    "\n",
    "def summarise_query_results(query_string, conn, max_items=10):\n",
    "    \"\"\"Print a short summary of the query results\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    result = cursor.execute(query_string).fetchall()\n",
    "    print(f\"{len(result)} rows returned\")\n",
    "    print('Column names: ', column_names(cursor))\n",
    "    limit = max_items if len(result) > max_items else len(result)\n",
    "    for i in range(limit):\n",
    "        print(result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_WEATHER_QUERY_INNER = '''\n",
    "SELECT\n",
    "    c.id as country_id\n",
    "    , c.name as country_name\n",
    "    , COUNT(w.date) as weather_records\n",
    "FROM\n",
    "    country c\n",
    "    INNER JOIN\n",
    "    weather w\n",
    "ON w.country_id = c.id\n",
    "GROUP BY c.id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 rows returned\n",
      "Column names:  ['country_id', 'country_name', 'weather_records']\n",
      "(1, 'UK', 7671)\n",
      "(2, 'FRANCE', 7671)\n",
      "(3, 'RUSSIA', 7671)\n",
      "(4, 'CANADA', 7671)\n"
     ]
    }
   ],
   "source": [
    "summarise_query_results(GET_WEATHER_QUERY_INNER, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_WEATHER_QUERY_OUTER = '''\n",
    "SELECT\n",
    "    c.id as country_id\n",
    "    , c.name as country_name\n",
    "    , COUNT(w.date) as weather_records\n",
    "FROM\n",
    "    country c\n",
    "    LEFT OUTER JOIN\n",
    "    weather w\n",
    "ON w.country_id = c.id\n",
    "GROUP BY c.id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 rows returned\n",
      "Column names:  ['country_id', 'country_name', 'weather_records']\n",
      "(1, 'UK', 7671)\n",
      "(2, 'FRANCE', 7671)\n",
      "(3, 'RUSSIA', 7671)\n",
      "(4, 'CANADA', 7671)\n",
      "(5, 'BRAZIL', 0)\n",
      "(6, 'AUSTRALIA', 0)\n"
     ]
    }
   ],
   "source": [
    "summarise_query_results(GET_WEATHER_QUERY_OUTER, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_WEATHER_QUERY_CROSS = '''\n",
    "SELECT\n",
    "    c.id as country_id\n",
    "    , c.name as country_name\n",
    "    , COUNT(w.date) as weather_records\n",
    "FROM\n",
    "    country c\n",
    "    CROSS JOIN\n",
    "    weather w\n",
    "GROUP BY c.id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 rows returned\n",
      "Column names:  ['country_id', 'country_name', 'weather_records']\n",
      "(1, 'UK', 30684)\n",
      "(2, 'FRANCE', 30684)\n",
      "(3, 'RUSSIA', 30684)\n",
      "(4, 'CANADA', 30684)\n",
      "(5, 'BRAZIL', 30684)\n",
      "(6, 'AUSTRALIA', 30684)\n"
     ]
    }
   ],
   "source": [
    "summarise_query_results(GET_WEATHER_QUERY_CROSS, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining many tables\n",
    "\n",
    "In the examples above, we are joining 2 tables together.\n",
    "\n",
    "In reality, we will often want to join more than 2 tables together. Are there additional considerations to bear in mind when joining on more than 2 tables?\n",
    "\n",
    "Other than wanting to avoid doing ***too many*** joins in any given query, no: the order in which we write the joins doesn't make any difference to the order in which the joins are executed because the optimiser will take its own view on how best to complete the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations & analytics\n",
    "\n",
    "- windows\n",
    "- pivots\n",
    "- rankings\n",
    "- histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHLY_PARTITION_QUERY = '''\n",
    "SELECT\n",
    "    c.name\n",
    "    , strftime('%Y-%m', w.date) as month\n",
    "    , w.date\n",
    "    , w.precip as daily_precip\n",
    "    , sum(w.precip) OVER (partition by strftime('%Y-%m', w.date) ROWS unbounded preceding) as sum_to_date\n",
    "    , sum(w.precip) OVER (ORDER BY w.date ROWS BETWEEN 9 PRECEDING AND 0 FOLLOWING) rolling_10d_precip_by_items\n",
    "    , sum(w.precip) OVER (ORDER BY w.date RANGE BETWEEN 9 PRECEDING AND 0 FOLLOWING) rolling_10d_precip_by_dates\n",
    "    , sum(w.precip) OVER (partition by strftime('%Y-%m', w.date)) as total_monthly_precip\n",
    "FROM\n",
    "    country c\n",
    "    INNER JOIN\n",
    "    weather w \n",
    "    ON\n",
    "    c.id = w.country_id\n",
    "WHERE\n",
    "    c.id = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7671 rows returned\n",
      "Column names:  ['name', 'month', 'date', 'daily_precip', 'sum_to_date', 'rolling_10d_precip_by_items', 'rolling_10d_precip_by_dates', 'total_monthly_precip']\n",
      "('UK', '2000-01', '2000-01-01', 13.6, 13.6, 13.6, 13.6, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-02', 0.0, 13.6, 13.6, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-03', 0.0, 13.6, 13.6, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-04', 0.0, 13.6, 13.6, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-05', 17.6, 31.200000000000003, 31.200000000000003, 17.6, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-06', 31.6, 62.800000000000004, 62.800000000000004, 31.6, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-07', 27.5, 90.30000000000001, 90.30000000000001, 27.5, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-08', 0.0, 90.30000000000001, 90.30000000000001, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-09', 0.0, 90.30000000000001, 90.30000000000001, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-10', 23.7, 114.00000000000001, 114.00000000000001, 23.7, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-11', 42.9, 156.9, 143.3, 42.9, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-12', 50.0, 206.9, 193.3, 50.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-13', 0.0, 206.9, 193.3, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-14', 0.0, 206.9, 193.3, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-15', 0.0, 206.9, 175.70000000000002, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-16', 16.9, 223.8, 161.00000000000003, 16.9, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-17', 19.1, 242.9, 152.60000000000002, 19.1, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-18', 50.0, 292.9, 202.60000000000002, 50.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-19', 0.0, 292.9, 202.60000000000002, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-20', 0.0, 292.9, 178.90000000000003, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-21', 0.0, 292.9, 136.00000000000003, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-22', 0.0, 292.9, 86.00000000000003, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-23', 9.1, 302.0, 95.10000000000002, 9.1, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-24', 25.3, 327.3, 120.40000000000002, 25.3, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-25', 17.6, 344.90000000000003, 138.00000000000003, 17.6, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-26', 21.5, 366.40000000000003, 142.60000000000002, 21.5, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-27', 0.0, 366.40000000000003, 123.50000000000003, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-28', 18.1, 384.50000000000006, 91.60000000000002, 18.1, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-29', 0.0, 384.50000000000006, 91.60000000000002, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-30', 0.0, 384.50000000000006, 91.60000000000002, 0.0, 384.50000000000006)\n",
      "('UK', '2000-01', '2000-01-31', 0.0, 384.50000000000006, 91.60000000000002, 0.0, 384.50000000000006)\n",
      "('UK', '2000-02', '2000-02-01', 40.6, 40.6, 132.20000000000002, 40.6, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-02', 18.7, 59.3, 141.8, 18.7, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-03', 3.0, 62.3, 119.50000000000001, 3.0, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-04', 24.3, 86.6, 126.2, 24.3, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-05', 26.1, 112.69999999999999, 130.8, 26.1, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-06', 19.1, 131.79999999999998, 149.9, 19.1, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-07', 26.3, 158.1, 158.10000000000002, 26.3, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-08', 0.0, 158.1, 158.10000000000002, 0.0, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-09', 40.9, 199.0, 199.00000000000003, 40.9, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-10', 0.0, 199.0, 199.00000000000003, 0.0, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-11', 0.5, 199.5, 158.90000000000003, 0.5, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-12', 0.9, 200.4, 141.10000000000005, 0.9, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-13', 50.0, 250.4, 188.10000000000005, 50.0, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-14', 0.0, 250.4, 163.80000000000004, 0.0, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-15', 47.1, 297.5, 184.80000000000004, 47.1, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-16', 20.6, 318.1, 186.30000000000004, 20.6, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-17', 24.7, 342.8, 184.70000000000002, 24.7, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-18', 0.0, 342.8, 184.70000000000002, 0.0, 422.40000000000003)\n",
      "('UK', '2000-02', '2000-02-19', 0.0, 342.8, 143.8, 0.0, 422.40000000000003)\n"
     ]
    }
   ],
   "source": [
    "summarise_query_results(MONTHLY_PARTITION_QUERY, conn, max_items=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idea-bank",
   "language": "python",
   "name": "idea-bank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
