{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "Notes from reading *Grokking Algorithms* by Aditya Bhargava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an algorithm?\n",
    "\n",
    "An algorithm is a set of instructions for accomplishing a task.\n",
    "\n",
    "There are often many ways to accomplish a task, and so we need to understand the trade-offs in order to know how best to accomplish a task in a given context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A motivating example: binary search\n",
    "\n",
    "Imagine that we need to find an element in a sorted list. More specifically, we want to return the position of the desired element in that list, or `null` if it cannot be found.\n",
    "\n",
    "**Simple search** might be the most obvious & basic attempt to solve that task. It starts at the first element, and moves through them one-by-one, in sequence, until it finds the right answer. If our desired value happens to be the first element, then we're in luck. If it isn't, and our list is long, then we might have to check a lot of values before we get our answer...\n",
    "\n",
    "**Binary search** dramatically reduces the number of values we have to check before we find the position of our desired element. At each step it selects the mid-point of the remaining elements and establishes whether that location is too low or too high in order to determine which elements it can remove from consideration, and which elements are still contenders (remember, it's a sorted list). This process is repeated with each step until we find the target value (or exhaust the possibilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def simple_search(sorted_elements: list, target_value: int) -> Union[int, None]:\n",
    "    for index, element in enumerate(sorted_elements):\n",
    "        if element == target_value:\n",
    "            return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sorted_list = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "print(simple_search(sorted_list, 3))\n",
    "print(simple_search(sorted_list, 6))\n",
    "print(simple_search(sorted_list, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 guesses\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_search(sorted_elements: list, target_value: int) -> Union[int, None]:\n",
    "    search_boundaries = {'low': 0, 'high': len(sorted_elements) - 1}\n",
    "    guesses = 0\n",
    "    while search_boundaries['low'] <= search_boundaries['high']:\n",
    "        mid_point = int((search_boundaries['low'] + search_boundaries['high']) / 2)\n",
    "        midpoint_value = sorted_elements[mid_point]\n",
    "        guesses += 1\n",
    "        if midpoint_value == target_value:\n",
    "            print(f\"{guesses} guesses\")\n",
    "            return mid_point\n",
    "        if midpoint_value > target_value:\n",
    "            search_boundaries['high'] = mid_point - 1\n",
    "        else:\n",
    "            search_boundaries['low'] = mid_point + 1\n",
    "    return\n",
    "\n",
    "binary_search([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Sort\\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursion\n",
    "\n",
    "A recursive recipe must contain three ingredients:\n",
    "\n",
    "1. Stopping criteria\n",
    "2. A first step (gets the ball rolling)\n",
    "3. A repetitive component (that will lead us to the stopping criteria) ie. a function that calls itself.\n",
    "\n",
    "Recursion does not improve computational performance, but may be faster to write. It should be used when it helps to make the solution easier to intuit.\n",
    "\n",
    "## Structure\n",
    "\n",
    "In order to avoid infinite loops of recursion, each recursive method needs to have two components:\n",
    "1. A base case: catches the stopping criteria & breaks the loop\n",
    "2. A recursive case: takes the recursion a layer deeper\n",
    "\n",
    "## The call stack\n",
    "\n",
    "The *stack* data structure acts like a LIFO inventory: new items go to the top of the pile as they're added and we remove those most recent items from the pile first as we work through it.\n",
    "\n",
    "The **call stack** is a stack data structure that our computers use to keep track of function calls that are WIP:\n",
    "- New function calls are added to the stack (memory is allocated to that call, and variables in that scope are saved to that memory)\n",
    "- Those function calls are removed from the stack as they return their results\n",
    "\n",
    "Because recursion involves calling the same function many times, with a chain of dependency between each call, it can lead to a lot of function calls being added to the call stack. With enough calls, or large state stored for each call, recursion can exhaust a machine's memory.\n",
    "\n",
    "When this occurs, there are two options:\n",
    "1. Use a loop instead\n",
    "2. Use tail recursion (which only some languages support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide & Conquer\n",
    "\n",
    "**Divide & Conquer** is a general technique for solving problems that uses recursion.\n",
    "\n",
    "1. Identify simple conditions in which the problem can be solved.\n",
    "2. Break the problem down so that you are only trying to solve it for increasingly small / simple inputs; continue until you reach a situation where you only need to deal with the simple conditions above. \n",
    "\n",
    "> NB. When working with recursion on problems involving arrays, the base / simple case is often a array of length 0 or 1.\n",
    "\n",
    "Preffering the recursive approach over loops is typical of **functional programming** - Haskell doesn't even have loops!\n",
    "\n",
    "The Binary Search algorithm that we saw earlier is also a type of D&C solution which can be coded using recursion. See the re-write of our earlier function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_binary_search(arr: list, target: int, low_idx: int, high_idx: int, guesses: int = 0) -> Union[int, None]:\n",
    "    if not low_idx < high_idx:\n",
    "        return None\n",
    "    guesses += 1\n",
    "    # Base case\n",
    "    mid_point = int(low_idx + (high_idx - low_idx) / 2)\n",
    "    print('mid: ', mid_point)\n",
    "    midpoint_value = arr[mid_point]\n",
    "    if midpoint_value == target:\n",
    "        print(f\"{guesses} guesses\")\n",
    "        return mid_point\n",
    "    elif midpoint_value > target:\n",
    "        return recursive_binary_search(arr, target, low_idx, mid_point-1, guesses=guesses)\n",
    "    else:\n",
    "        return recursive_binary_search(arr, target, mid_point+1, high_idx, guesses=guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid:  10\n",
      "mid:  4\n",
      "2 guesses\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "recursive_binary_search(arr, 4, 0, len(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicksort\n",
    "\n",
    "Quicksort - as the name suggests - is a sorting algorithm that uses D&C.\n",
    "\n",
    "We'll work through it using the example of sorting an array:\n",
    "\n",
    "**1. Identify simple conditions in which the problem can be solved.**\n",
    "\n",
    "The simplest situation we can hope to work with is a case where the array is either empty, or only has one element: in this scenario, we can just return the array as it is because there's no sorting to be done!\n",
    "\n",
    "This could look something like:\n",
    "```python\n",
    "def quicksort(arr):\n",
    "    if len(arr) < 2:\n",
    "        return arr\n",
    "```\n",
    "\n",
    "The next simplest situation we can have is an array with 2 elements. In this scenario, if the first element is larger than the second, then swap them around and return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quicksort(arr):\n",
    "    if len(arr) < 2:\n",
    "        return arr\n",
    "    if len(arr) == 2:\n",
    "        return arr if arr[0] < arr[1] else arr[::-1]\n",
    "    \n",
    "quicksort([2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Then break the problem down until you reach those conditions.**\n",
    "\n",
    "And now we need to think through how we'd approach longer arrays. With 3 elements, we can no longer do the direct comparison above. We need to Divide & Conquer... How could we break up the process so that we end up only having to deal with many instances of the base case?\n",
    "\n",
    "One approach could be to:\n",
    "- Select an element; we'll call our selected element the ***pivot***\n",
    "- Work through & throw all other elements into one of two buckets (leaving three in total, once the pivot is included): those less than the pivot, and those greater than the pivot\n",
    "- For each of the non-pivot buckets, choose a new pivot and repeat\n",
    "- Eventually, each non-pivot bucket will simplify to an array of 2 or fewer elements, and from these we can build a complete array of sorted elements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1]\n",
      "[5, 4]\n"
     ]
    }
   ],
   "source": [
    "lesser = []\n",
    "greater = []\n",
    "arr = [5,4,3,2,1]\n",
    "pivot = 3\n",
    "\n",
    "for elem in arr:\n",
    "    lesser.append(elem) if elem <= pivot else greater.append(elem)\n",
    "    \n",
    "print(lesser)\n",
    "print(greater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quicksort(arr: list):\n",
    "    if len(arr) < 2:\n",
    "        return arr\n",
    "    if len(arr) == 2:\n",
    "        return arr if arr[0] < arr[1] else arr[::-1]\n",
    "    \n",
    "    lesser = []\n",
    "    greater = []\n",
    "    pivot = arr.pop()\n",
    "    for elem in arr:\n",
    "        lesser.append(elem) if elem <= pivot else greater.append(elem)\n",
    "    \n",
    "    return quicksort(lesser) + [pivot] + quicksort(greater)\n",
    "    \n",
    "\n",
    "assert quicksort([1, 2]) == [1, 2]\n",
    "assert quicksort([1, 2, 3]) == [1, 2, 3], f\"returns {quicksort([1,2,3])}\"\n",
    "assert quicksort([7, 6, 5, 4, 2, 3, 1]) == [1, 2, 3, 4, 5, 6, 7], f\"returns {quicksort([1,2,3,4,5,6,7])}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on complexity\n",
    "\n",
    "The speed with which quicksort sorts an array depends on which pivots we choose:\n",
    "- In the worst case, the complexity of running quicksort is $O(n^{2})$ (ie. as bad as **selection sort**)\n",
    "- In the average case, the complexity of running quicksort is $O(nlog(n))$\n",
    "\n",
    "The worst case occurs if we manage to always select our pivot such that all remaining elements lie in just one partition (ie. all are lesser than, or greater than, the pivot). This results in the worst case, because we're effectively removing one item from the array at a time, rather than breaking it into many chunks. This would occur when the array passed in is already sorted and we select the first element as pivot on each split.\n",
    "\n",
    "To avoid the worst case, and aim for the average case, we usually select the pivot element by random each split.\n",
    "\n",
    "In contrast, the best case occurs if each pivot is bang in the middle of the array, so the partitions are split equally - which speeds up how quickly we break all branches down to a base case scenario. In this case, the runtime complexity is $O(log(n))$.\n",
    "\n",
    "The average case complexity is equal to the best case complexity! (the runtime will be slower because we're unlikely to get exactly the ideal splits every time, but it scales with $n$ in the same order of complexity).\n",
    "\n",
    "### Parallelism?\n",
    "\n",
    "Looking at the shape of the quicksort method we've written above, it's interesting to see that not only are we using recursion, we're using recursion twice (in that last line).\n",
    "The fact that we're breaking the problem down into many branching pieces more quickly (by calling it twice, rather than having a single chain of many dependent calls) suggests that there may be more opportunity for parallel processing to help us here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge sort\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg-case Vs Worst case\n",
    "\n",
    "In all the complexity notation, there's a hidden constant; figuratively and literally...\n",
    "\n",
    "In all cases, the runtime of an algorithm depends not just on $n$, but also $c$: the time taken to compute the required operations for each element of $n$.\n",
    "For some algorithms, the order of complexity may be higher than others, but $c$ may be small enough that it's still faster to use for the size of $n$ you're dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "\n",
    "| Algorithm     | Worst-case runtime complexity      |\n",
    "|:--------------|:-------------:|\n",
    "| Binary search |  |\n",
    "| Selection sort|     $O(n^{n}$     |\n",
    "| Quicksort     |          |\n",
    "| Merge sort    |          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "[Eliana Lopez's crib sheet](https://github.com/elianalopez/Data-Structures-and-Algorithms-Notes-with-Python)\n",
    "[Complexity of Python Operations](https://www.ics.uci.edu/~pattis/ICS-33/lectures/complexitypython.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
